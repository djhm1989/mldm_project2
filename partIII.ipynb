{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Ensembles and Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import proj2_lib.util as utils\n",
    "file_config = utils.file_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RUN_MAKE_TRAIN_TEST_FILES = False\n",
    "if RUN_MAKE_TRAIN_TEST_FILES:\n",
    "    utils.make_train_test_sets(config=file_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import proj2_lib.preprocess as preprocess\n",
    "\n",
    "RUN_FIT_PREPROCESSING = False\n",
    "if RUN_FIT_PREPROCESSING:\n",
    "    preprocess.fit_save_pipelines(config=file_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90526, 101) (90526,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = preprocess.load_train_data(config=file_config)\n",
    "print(train_X.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 101) (20000,)\n"
     ]
    }
   ],
   "source": [
    "test_X, test_y = preprocess.load_test_data(config=file_config)\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## AdaBoost\n",
    "\n",
    "Train an AdaBoost classifier using Decision Tree stubs as weak learners. Compare its performance to results obtained in Part II using 10 fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy mean:  0.797494628163\n",
      "AdaBoost AUC mean:  0.727120212485\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost code goes here\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "adaboost_clf = AdaBoostClassifier()\n",
    "#adaboost_clf.fit(train_X,train_y)\n",
    "#base_estimator : object, optional (default=DecisionTreeClassifier)\n",
    "\n",
    "ada_accuracy = cross_val_score(adaboost_clf, train_X, train_y, \n",
    "                                 scoring='accuracy', cv=10)\n",
    "print('AdaBoost Accuracy mean: ', np.mean(ada_accuracy))\n",
    "\n",
    "ada_auc = cross_val_score(adaboost_clf, train_X, train_y, \n",
    "                          scoring=\"roc_auc\", cv=10)\n",
    "print('AdaBoost AUC mean: ', np.mean(ada_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the performance:\n",
    "  - best performance in PartII is RandomForest Classifier, with AUC mean of 0.6932 .  \n",
    "  - AdaBoost Classifier, with AUC mean is 0.7271,   \n",
    "      which is better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking\n",
    "\n",
    "Choose a set of 5 or so classifiers. Write a function that trains an ensemble using stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def build_stack_ensemble(X, y):\n",
    "    # create train/validation sets\n",
    "    # using StratifiedShuffleSplit\n",
    "    split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=1234)\n",
    "    \n",
    "    for train_index, valid_index in split.split(X,y):\n",
    "        x_train = X[train_index] \n",
    "        y_train = y[train_index]\n",
    "        x_valid = X[valid_index]\n",
    "        y_valid = y[valid_index]\n",
    "    \n",
    "    # train classifiers in ensemble using train set\n",
    "    tree_classifier = DecisionTreeClassifier(max_depth=5)\n",
    "    tree_1 = tree_classifier.fit(x_train,y_train)\n",
    "    \n",
    "    tree_classifier = DecisionTreeClassifier(max_depth=30)\n",
    "    tree_2 = tree_classifier.fit(x_train,y_train)\n",
    "    \n",
    "    rf_classifier = RandomForestClassifier(n_estimators=10)\n",
    "    rf_1 = rf_classifier.fit(x_train,y_train)\n",
    "    \n",
    "    rf_classifier = RandomForestClassifier(n_estimators=30)\n",
    "    rf_2 = rf_classifier.fit(x_train,y_train)\n",
    "    \n",
    "    linear_svm = LinearSVC(dual=False)\n",
    "    lsvm_1 = linear_svm.fit(x_train,y_train)\n",
    "    \n",
    "    #rbf_svm = SVC(kernel='rbf', gamma='auto')\n",
    "    #svm_clf = rbf_svm.fit(x_train,y_train)\n",
    "    \n",
    "    \n",
    "    # create new feature matrix for validation\n",
    "    # set by getting predictions from the ensemble\n",
    "    # classifiers\n",
    "    predicts = []\n",
    "    tr_predict_1 = tree_1.predict(x_valid)\n",
    "    predicts.append(tr_predict_1)\n",
    "    \n",
    "    tr_predict_2 = tree_2.predict(x_valid)\n",
    "    predicts.append(tr_predict_2)\n",
    "    \n",
    "    rf_predict_1 = rf_1.predict(x_valid)\n",
    "    predicts.append(rf_predict_1)\n",
    "    \n",
    "    rf_predict_2 = rf_2.predict(x_valid)\n",
    "    predicts.append(rf_predict_2)\n",
    "\n",
    "    lsvm_predict_1 = lsvm_1.predict(x_valid)\n",
    "    predicts.append(lsvm_predict_1)\n",
    "    \n",
    "\n",
    "    pre_mat = np.array(predicts)\n",
    "    \n",
    "    predicts_mat = np.transpose(pre_mat)\n",
    "    \n",
    "    # train logistic regression classifier on\n",
    "    # new feature matrix\n",
    "    lr = LogisticRegression()\n",
    "    lr_clf = lr.fit(predicts_mat,y_valid)\n",
    "    \n",
    "    #pred_lr = lr.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # return all trained classifiers\n",
    "    return tree_1,tree_2,rf_1,rf_2,lsvm_1,lr_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 10-fold cross validation to measure performance of your stacked classifier. See Part II solution to see how to roll your own sklearn classifier along with http://scikit-learn.org/stable/developers/contributing.html#rolling-your-own-estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "class StackClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        self.tree_1_, self.rf_1_ ,\\\n",
    "        self.lsvm_1_, self.tree_2_,\\\n",
    "        self.rf_2_ , self.lr_clf_ = build_stack_ensemble(X, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        check_is_fitted(self, ['tree_1_', 'rf_1_', 'lsvm_1_', \n",
    "                               'tree_2_', 'rf_2_','lr_clf_'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "\n",
    "        predicts = []\n",
    "        predicts.append(self.tree_1_.predict(X))\n",
    "        predicts.append(self.tree_2_.predict(X))\n",
    "        predicts.append(self.rf_1_.predict(X))\n",
    "        predicts.append(self.rf_2_.predict(X))\n",
    "        predicts.append(self.lsvm_1_.predict(X))\n",
    "        \n",
    "        pre_mat = np.array(predicts)\n",
    "        \n",
    "        predicts_mat = np.transpose(pre_mat)\n",
    "        \n",
    "        return self.lr_clf_.predict(predicts_mat)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        f = self.decision_function(X)\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Classifier's Accuracy mean:  0.798190559361\n"
     ]
    }
   ],
   "source": [
    "stack_clf = StackClassifier()\n",
    "\n",
    "stack_accuracy = cross_val_score(stack_clf, train_X, train_y, \n",
    "                                 scoring='accuracy', cv=10)\n",
    "print('Stacked Classifier\\'s Accuracy mean: ',np.mean(stack_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Classifier's AUC mean:  0.501799617978\n"
     ]
    }
   ],
   "source": [
    "stack_auc = cross_val_score(stack_clf, train_X, train_y,\n",
    "                          scoring='roc_auc', cv=10)\n",
    "\n",
    "print('Stacked Classifier\\'s AUC mean: ',np.mean(stack_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Result\n",
    "\n",
    "Choose a single model based on all previous project steps. Train this model on the complete training dataset and measure it's performance on the held out test set.\n",
    "\n",
    "Compare to the 10-fold CV estimate you got previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final result goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboost Classifier got the highest AUC score, 0.7271  \n",
    "I choose Adaboost Classifier to train it with complete trainning dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Clf's AUC on Test Set:  0.504526329102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "adaboost_clf = AdaBoostClassifier()\n",
    "adaboost_clf.fit(train_X,train_y)\n",
    "\n",
    "test_predict=adaboost_clf.predict(test_X)\n",
    "\n",
    "auc_score=roc_auc_score(test_y,test_predict)\n",
    "print('Adaboost Clf\\'s AUC on Test Set: ',auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC score is much lower than we got before. Not a good performance.   \n",
    "Try out other model below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacked Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack Clf's AUC on Test Set:  0.501789705313\n"
     ]
    }
   ],
   "source": [
    "stack_clf = StackClassifier()\n",
    "stack_clf.fit(train_X,train_y)\n",
    "\n",
    "test_predict=stack_clf.predict(test_X)\n",
    "\n",
    "auc_score=roc_auc_score(test_y,test_predict)\n",
    "print('Stack Clf\\'s AUC on Test Set: ',auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Clf's AUC on Test Set:  0.565270859604\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=30)\n",
    "rf_clf.fit(train_X,train_y)\n",
    "\n",
    "test_predict=rf_clf.predict(test_X)\n",
    "\n",
    "auc_score=roc_auc_score(test_y,test_predict)\n",
    "print('RandomForest Clf\\'s AUC on Test Set: ',auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Clf's AUC on Test Set:  0.532471774982\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=20)\n",
    "tree_clf.fit(train_X,train_y)\n",
    "\n",
    "test_predict=tree_clf.predict(test_X)\n",
    "\n",
    "auc_score=roc_auc_score(test_y,test_predict)\n",
    "print('DecisionTree Clf\\'s AUC on Test Set: ',auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Clf's AUC on Test Set:  0.501732667919\n"
     ]
    }
   ],
   "source": [
    "lsvm_clf = LinearSVC(dual=False)\n",
    "lsvm_clf.fit(train_X,train_y)\n",
    "\n",
    "test_predict=lsvm_clf.predict(test_X)\n",
    "\n",
    "auc_score=roc_auc_score(test_y,test_predict)\n",
    "print('DecisionTree Clf\\'s AUC on Test Set: ',auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Linear SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-linear SVM 's AUC on Test Set:  0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "rbf_svm = SVC(kernel='rbf', gamma='auto')\n",
    "rbf_svm.fit(train_X,train_y)\n",
    "\n",
    "test_predict=rbf_svm.predict(test_X)\n",
    "\n",
    "auc_score=roc_auc_score(test_y,test_predict)\n",
    "print('Non-linear SVM \\'s AUC on Test Set: ',auc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
